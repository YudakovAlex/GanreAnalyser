{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only variable you need to specify is music library location\n",
    "misuc_lib_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import requests as req\n",
    "from pyquery import PyQuery\n",
    "from datetime import datetime\n",
    "import json\n",
    "from itertools import combinations\n",
    "import math\n",
    "import sklearn as sk # sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is one part that is written not in Python: conversion mp3 to wav is done via Linux app called \"mpg321\" in function convert_mp3_to_wav. Everything else is Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General functions and variables\n",
    "gradual_steps = [10, 50, 100, 500, \n",
    "     1000, 5000, 10000, 50000,\n",
    "     100000, 500000, 1000000, 5000000, \n",
    "     10000000, 50000000, 100000000, 500000000, \n",
    "     1000000000, 5000000000, 10000000000, 50000000000]\n",
    "\n",
    "def large_int_print(num):\n",
    "    final_str = \"\"\n",
    "    num_str = list(str(num))\n",
    "    section_size=0\n",
    "    while num_str:\n",
    "        final_str+=num_str.pop()\n",
    "        if section_size>0 and section_size==2 and len(num_str)!=0:\n",
    "            final_str+=\",\"\n",
    "            section_size=0\n",
    "        else:\n",
    "            section_size+=1\n",
    "    return final_str[::-1]\n",
    "\n",
    "def get_time_left(start_time, total_items, done_items):\n",
    "    time_spent = datetime.now() - start_time\n",
    "    if time_spent.seconds==0: return \"?\"\n",
    "    rate_ps = done_items / time_spent.seconds\n",
    "    if rate_ps==0: return \"?\"\n",
    "    return print_time(sec_num=round((total_items - done_items)/rate_ps,2))\n",
    "\n",
    "def print_time(sec_num=None, time_dif=None):\n",
    "    \"Pring nice time from number of seconds or time_dif object\"\n",
    "    if not sec_num:\n",
    "        if time_dif:\n",
    "            sec_num = time_dif.seconds\n",
    "        else:\n",
    "            print(\"No values provided for time prointing.\")\n",
    "            return None\n",
    "    if sec_num < 60:\n",
    "        return str(round(sec_num)) + \"s\"\n",
    "    elif sec_num >= 60 and sec_num < 60*60:\n",
    "        return (\n",
    "            str(round(sec_num//60)) + \"m\" \n",
    "            + str(round(sec_num%60)) + \"s\")\n",
    "    else:\n",
    "        return (\n",
    "            str(round(sec_num//(60*60))) + \"h\" \n",
    "            + str(round((sec_num%(60*60))//60)) + \"m\" \n",
    "            + str(round(sec_num%60)) + \"s\")\n",
    "\n",
    "def print_dict(d, sample):\n",
    "    for i, (k, v) in enumerate(d.items()):\n",
    "        print(k,\":\",v)\n",
    "        if i>=sample:\n",
    "            break\n",
    "            \n",
    "def get_pretty_volume(bytes_num):\n",
    "    num_size = len(str(bytes_num)) / 3\n",
    "    def p(val, pow):\n",
    "        return str(round(val/(1024**pow), 2))\n",
    "    if num_size > 5: return p(bytes_num,5) + \" pb\"\n",
    "    elif num_size > 4: return p(bytes_num,4) + \" tb\"\n",
    "    elif num_size > 3: return p(bytes_num,3) + \" gb\"\n",
    "    elif num_size > 2: return p(bytes_num,2) + \" mb\"\n",
    "    elif num_size > 1: return p(bytes_num,1) + \" kb\"\n",
    "    else: return str(bytes_num) + \" bytes\"\n",
    "    \n",
    "def remove_files(lib_path, ext_filter, limit_num):\n",
    "    log(\"Removing\",ext_filter,\"files from\",lib_path)\n",
    "    files = get_all_files(lib_path, ext_filter=ext_filter)\n",
    "    if limit_num: \n",
    "        to_remove_num = limit_num\n",
    "        log(\"Found\",len(files),\"will remove\",limit_num,\"of them.\")\n",
    "    else:\n",
    "        to_remove_num = len(files)\n",
    "        log(\"Found\",len(files),\"will remove all of them.\")\n",
    "    freed_space = 0\n",
    "    for i, file in enumerate(files):\n",
    "        if i >= to_remove_num: break\n",
    "        if os.path.isfile(file):\n",
    "            freed_space += os.path.getsize(file)\n",
    "            os.remove(file)\n",
    "        else:\n",
    "            log(file, \"is not a file.\")\n",
    "        if ((i+1)==10 or (i+1)==50 or (i+1)%100==0):\n",
    "            log(\"Removed\", (i+1), \"files. Freed up\", get_pretty_volume(freed_space))\n",
    "    log(\"Finished cleaning library.\\n\\tRemoved\", to_remove_num, \n",
    "        \"files. Freed up\", get_pretty_volume(freed_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(path, ext_filter=\"MP3\"):\n",
    "    w = os.walk(path)\n",
    "    # folder / subfolders / files\n",
    "    all_files = []\n",
    "    for sw in w:\n",
    "        all_files += [sw[0] + \"/\" + x for x in sw[2]]\n",
    "    files = []\n",
    "    for f in all_files:\n",
    "        if f.split(\".\")[-1].upper() == ext_filter.upper():\n",
    "            files.append(f)\n",
    "    return files\n",
    "\n",
    "def convert_mp3_to_wav(filename_mp3, filename_wav=None):\n",
    "    cd = os.getcwd() # If filename doesn't contain path, use current directory\n",
    "    if \"/\" not in filename_mp3:\n",
    "        filename_mp3 = cd + \"/\" + filename_mp3\n",
    "    filename_wav =  \".\".join(filename_mp3.split(\".\")[0:-1]) + \".wav\"\n",
    "    subprocess.run([\"mpg321\", \"-w\", filename_wav, filename_mp3])\n",
    "    return filename_wav\n",
    "\n",
    "def get_wav_data_old(filepath, bucket_width=100):\n",
    "    \"\"\" \n",
    "    Data of wav file is very much narrowed down to what I want to analyse. \n",
    "    So if you want to analyse in your own way, this is the function to change.\n",
    "    \"\"\"\n",
    "    fs, data = wavfile.read(filepath)\n",
    "    df_data = pd.DataFrame(data)\n",
    "    df_data['max'] = df_data.max(axis=1)\n",
    "    df_data['buckets'] = pd.Series(df_data['max']/bucket_width).astype(int)\n",
    "    bucket_sizes = df_data.groupby('buckets').size()\n",
    "    bucket_sizes = bucket_sizes.drop(bucket_sizes.idxmax())\n",
    "    return (bucket_sizes/max(bucket_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_wav_data(filepath, **kwargs):\n",
    "    try:\n",
    "        fs, data = wavfile.read(filepath)\n",
    "        df_data = pd.DataFrame(data)\n",
    "        df_data['max'] = df_data.max(axis=1)\n",
    "    except Exception as e:\n",
    "        print(\"Failed to read\",filepath)\n",
    "        raise\n",
    "    return df_data\n",
    "\n",
    "def get_experimental_wav_data(filepath, buckets_num=100):\n",
    "    try:\n",
    "        fs, data = wavfile.read(filepath)\n",
    "        df_data = pd.DataFrame(data)\n",
    "        df_data['max'] = df_data.max(axis=1)\n",
    "        #df_data['scale'] = (df_data['max'] + 32768) / (32768 + 32767) # -32768 32767\n",
    "        if df_data['max'].max() > 32767 or df_data['max'].min() < -32768:\n",
    "            print(\"!!! Something wrong with scale !!!\")\n",
    "        df_data['bucket'] = ((df_data['max'] + 32768) / ((32768 + 32767) / buckets_num)).astype('int')\n",
    "        bucket_sizes = df_data.groupby('bucket').count()\n",
    "        bucket_sizes = bucket_sizes.drop(bucket_sizes.idxmax())\n",
    "        bucket_sizes['max'] = bucket_sizes['max'] / bucket_sizes['max'].max()\n",
    "    except Exception as e:\n",
    "        print(\"Failed to read\",filepath)\n",
    "        raise\n",
    "    return pd.Series(bucket_sizes['max'])\n",
    "\n",
    "def get_wav_data(filepath, bucket_width=100):\n",
    "    \"\"\" \n",
    "    Data of wav file is very much narrowed down to what I want to analyse. \n",
    "    So if you want to analyse in your own way, this is the function to change.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fs, data = wavfile.read(filepath)\n",
    "        df_data = pd.DataFrame(data)\n",
    "        df_data['max'] = df_data.max(axis=1)\n",
    "        df_data['buckets'] = (df_data['max']/bucket_width).astype('int')\n",
    "        bucket_sizes = df_data.groupby('buckets').count()\n",
    "        bucket_sizes = bucket_sizes.drop(bucket_sizes.idxmax())\n",
    "    except Exception as e:\n",
    "        print(\"Failed to read\",filepath)\n",
    "        raise\n",
    "    return bucket_sizes.index/bucket_sizes['max'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log(*args):\n",
    "    print(datetime.now(), \" \".join([str(a) for a in args]))\n",
    "    \n",
    "def process_library(\n",
    "        lib_path, \n",
    "        proc_func=None, \n",
    "        max_files=None, \n",
    "        partial_data=None,\n",
    "        number_of_buckets=100,\n",
    "        keep_wav=True):\n",
    "    \"\"\"\n",
    "    For all mp3 files in the lib:\n",
    "        - Convert to wav, if wav doesn't exists\n",
    "        - Get aggregated data from wav file\n",
    "    \"\"\"\n",
    "    log(\"Analyzing library...\")\n",
    "    lib_data = pd.DataFrame(columns=list(range(number_of_buckets+1)))\n",
    "    if not partial_data.empty: \n",
    "        lib_data = partial_data\n",
    "        log(\"Recieved data of\",len(lib_data),\"processed files.\")\n",
    "    process_counter = 0\n",
    "    convert_counter = 0\n",
    "    skipped = []\n",
    "    log(\"Begining library scan...\")\n",
    "    files_to_process = get_all_files(lib_path, ext_filter=\"MP3\")\n",
    "    log(\"Library is scanned. Found\", len(files_to_process), \"mp3 files.\")\n",
    "    if max_files:\n",
    "        log(\"Files to process:\",max_files)\n",
    "    else:\n",
    "        log(\"Files to process:\",len(files_to_process))\n",
    "    log(\"Begin library processing...\")\n",
    "    start_time = datetime.now()\n",
    "    if max_files:\n",
    "        total_to_proc = max_files\n",
    "    else:\n",
    "        total_to_proc = len(all_data_long) - len(files_to_process)\n",
    "    for mp3_file in files_to_process:\n",
    "        if mp3_file in lib_data.index:\n",
    "            continue\n",
    "        try:\n",
    "            wav_file = (\".\".join(mp3_file.split(\".\")[0:-1]) + \".wav\")\n",
    "            if not os.path.isfile(wav_file):\n",
    "                # I'm saving wav next to mp3, you can change it here.\n",
    "                wav_file = convert_mp3_to_wav(mp3_file, wav_file)\n",
    "                convert_counter+=1\n",
    "            wav_data = proc_func(wav_file, buckets_num=100) #bucket_width=300)\n",
    "            # ? Save the thing into sepate json next to wav and mp3 for each song? \n",
    "            if not keep_wav:\n",
    "                os.remove(wav_file)\n",
    "            lib_data.loc[mp3_file] = wav_data\n",
    "            process_counter+=1\n",
    "            if (process_counter in gradual_steps or process_counter%1000==0):\n",
    "                log(\"Processed\", process_counter,\n",
    "                    \"files, of them converted\", convert_counter, \"\\n\\tTime left:\", \n",
    "                    get_time_left(start_time, total_to_proc, process_counter),\n",
    "                    \" | Dataframe volume:\", \n",
    "                    get_pretty_volume(sys.getsizeof(lib_data)))\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't process:\\n\", mp3_file, \"\\n\", wav_file, str(e))\n",
    "            skipped.append(mp3_file)\n",
    "        if max_files: \n",
    "            if process_counter>=max_files: \n",
    "                break\n",
    "    log(\"Finished!\\n\\tSongs processed:\", len(lib_data), \"of\", len(files_to_process),\n",
    "        \"\\n\\tDataframe valume:\", get_pretty_volume(sys.getsizeof(lib_data)),\n",
    "        \"\\n\\tSkipped:\", len(skipped), \"files\",\n",
    "        \"\\n\\tTime spent:\", print_time(time_dif=datetime.now()-start_time)\n",
    "        )\n",
    "    return skipped, lib_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_dump_file_path = misuc_lib_path + \"/Full_Data.json\" # Your data dump file will be here\n",
    "proc_round = 0\n",
    "\n",
    "def prepare_data(lib_path, dump_path, file_limit):\n",
    "    global proc_round\n",
    "    proc_round+=1\n",
    "    print(\"Round\",proc_round)\n",
    "    \n",
    "    # Load if json exists\n",
    "    all_data = pd.DataFrame() # Dict that contains DataFrame and song names as keys\n",
    "    if os.path.isfile(dump_path):\n",
    "        all_data = pd.read_json(dump_path)\n",
    "\n",
    "    # Keeping whole file paths to be able to manipulate files later\n",
    "    (skipped_files, all_data) = process_library(\n",
    "        misuc_lib_path,\n",
    "        proc_func=get_experimental_wav_data,\n",
    "        max_files=file_limit,\n",
    "        partial_data=all_data,\n",
    "        keep_wav=True)\n",
    "\n",
    "    # Save results into json\n",
    "    # Dumping doesn't work for now, due to issut with dumping the whole thing\n",
    "    all_data.to_json(dump_path)\n",
    "    print(\"Data is dumped to\",dump_path)\n",
    "    print(\"\\n\\n\")\n",
    "    return all_data\n",
    "\n",
    "\"! Warning ! WAV files takes about 10 times more space then MP3! Beware of free space on your disc.\"\n",
    "cycles_to_run = 1\n",
    "nuber_of_files_per_cycle = 6\n",
    "\n",
    "for i in range(cycles_to_run): # Iterate to have regular dumps, think this way is more reliable\n",
    "    all_data_long = prepare_data(\n",
    "        misuc_lib_path, \n",
    "        full_data_dump_file_path, \n",
    "        nuber_of_files_per_cycle)\n",
    "log(\"Finished processing.\")\n",
    "    \n",
    "# Clean names (shorten for convinience and memory optimization), saves as a separate dataframe\n",
    "# Keeping 2 data structures for experimentation convinience, feel free to use only one and remove another!\n",
    "#all_data_clean_dict = {k[len(misuc_lib_path):]:v for k, v in all_data.items()}\n",
    "#all_data_df = pd.DataFrame([(k[len(misuc_lib_path):], v) for k, v in all_data.items()])\n",
    "#print(\"Lib path is removed from file names, dictionary is converted to DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_songs(buckets_df, sample_size=None):\n",
    "    \"Compares songs. Approx 100.000 songs a minute for 100-column df\"\n",
    "    log(\"Begining comparison...\")\n",
    "    all_combinations = pd.DataFrame(\n",
    "        data=[[s1,s2,None] for s1, s2 in combinations(list(buckets_df.index)[:sample_size], 2)], \n",
    "        columns=[\"Song1\", \"Song2\", \"Distance\"])\n",
    "    #all_combinations[\"Distance\"] = pd.to_numeric(all_combinations[\"Distance\"])\n",
    "    \n",
    "    if sample_size:\n",
    "        total_to_proc = sample_size\n",
    "    else:\n",
    "        total_to_proc = len(buckets_df)\n",
    "    log(\"Of\",total_to_proc,\"of songs, number of unique pairs:\",\n",
    "        large_int_print(len(all_combinations)))\n",
    "    start_time = datetime.now()\n",
    "    for index, row in all_combinations.iterrows():\n",
    "        if index+1 in gradual_steps[4:] or (index+1)%1000000==0: \n",
    "            log(\"Processed\", large_int_print(index+1), \n",
    "                \"rows. Approximate time left:\",\n",
    "                get_time_left(start_time, len(all_combinations), index+1))\n",
    "            \n",
    "            # Size of DF?\n",
    "            \n",
    "        song1_name = row[0] \n",
    "        song2_name = row[1]\n",
    "        if song1_name == song2_name:\n",
    "            print(\"Comparing to itself :(\")\n",
    "        song1_data = all_data_long.loc[song1_name].copy()\n",
    "        song2_data = all_data_long.loc[song2_name].copy()\n",
    "        #all_combinations.iloc[index][\"Distance\"] = sum_of_abs_of_arrays(\n",
    "        #    pd.Series(song1_data - song2_data))\n",
    "        all_combinations.iloc[index][\"Distance\"] = abs((song1_data - song2_data)).sum()\n",
    "    all_combinations[\"Distance\"] = pd.to_numeric(all_combinations[\"Distance\"])\n",
    "    log(\"Completed comparison of\",total_to_proc,\"songs.\",\n",
    "       \"Time spent:\", print_time(time_dif=datetime.now()-start_time))\n",
    "    return all_combinations\n",
    "\n",
    "#comb = compare_all_songs(all_data_long, sample_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.Series\n",
    "comb = compare_all_songs(all_data_long, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = compare_all_songs(all_data_long, sample_size=10)\n",
    "s = comb[\"Song1\"]\n",
    "#comb[\"Song1\"] = comb[\"Song1\"][len(\"/media/shad/DATA/MuzAnalysis/\"):]\n",
    "#comb.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb = compare_all_songs(all_data_long, sample_size=100)\n",
    "for i in range(1,3):\n",
    "    comb[\"Song\" + str(i)] = pd.Series(\n",
    "        comb[\"Song\" + str(i)]).str.slice(\n",
    "            start=len(misuc_lib_path))\n",
    "\n",
    "for i in range(1,3):\n",
    "    comb[\"Song\" + str(i)] = pd.Series(\n",
    "        comb[\"Song\" + str(i)]).str.split(\"/\", expand=True)\n",
    "\n",
    "#gr = (columns=[\"Song1\",\"Song2\",\"Mean Distance\",\"Number of songs\"])\n",
    "gr = pd.DataFrame(comb.groupby([\"Song1\",\"Song2\"])[\"Distance\"].mean())\n",
    "gr[\"Number of pairs\"] = comb.groupby([\"Song1\",\"Song2\"])[\"Distance\"].count()\n",
    "#gr = comb.groupby([\"Song1\", \"Song2\"], as_index=True, axis=1)\n",
    "#(comb.groupby([\"Song1\", \"Song2\"], index=False)).mean()[\"Distance\"]\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.to_csv(misuc_lib_path + \"/comaprison_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb.to_json(misuc_lib_path + \"/comaprison_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = sk.linear_model.LogisticRegression(\n",
    "    penalty=’l2’, \n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    class_weight=None, \n",
    "    random_state=None, \n",
    "    solver=’warn’, \n",
    "    max_iter=100, \n",
    "    multi_class=’warn’, \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    n_jobs=None, \n",
    "    l1_ratio=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment starting from here\n",
    "### Everythin that follows is in very raw state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_sample = 3 # Limit sample of songs to build charts\n",
    "for k, v in all_data.items():\n",
    "    if chart_sample > 0:\n",
    "        chart_sample-=1\n",
    "        print(k)\n",
    "        plt.plot(v)\n",
    "        plt.show()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combinations(data_dict):\n",
    "    # Make a list of all combinations, to have list of comparisons.\n",
    "    prodj = combinations(list(data_dict.keys()), 2)\n",
    "    prodj = list(prodj)\n",
    "    print(\"Number of possible comparisons:\", len(list(prodj)))\n",
    "    return prodj\n",
    "\n",
    "#comb = make_combinations(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "# Check out all combination pairs\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_songs(prodj, data_dict):\n",
    "    print(\"Pairs to compare: \" + str(len(prodj)))\n",
    "    comparing_data = pd.DataFrame(columns=['song1','song2','dif'])\n",
    "    comparing_data[\"dif\"] = pd.to_numeric(comparing_data[\"dif\"]) \n",
    "\n",
    "    comparing_counter = 0\n",
    "    for song1_name, song2_name in prodj:\n",
    "        try:\n",
    "            if song1_name == song2_name:\n",
    "                print(\"Comparing to itself :(\")\n",
    "            if song1_name[0] == song2_name[0]:\n",
    "                pass\n",
    "            \n",
    "            result = pd.concat([\n",
    "                data_dict[song1_name],\n",
    "                data_dict[song2_name]\n",
    "                ], \n",
    "                keys=[0,1],\n",
    "                axis=1, join='outer').fillna(0) #join_axes=[song1_data.index]\n",
    "            result['dif'] = (abs(result[0] - result[1])).astype('float')\n",
    "            res_list = [song1_name, song2_name, sum(result['dif'])]\n",
    "            if res_list[2] != 0:\n",
    "                comparing_data.loc[len(comparing_data)] = res_list\n",
    "        except Exception as e:\n",
    "            print(\"Issue with\", song1_name, \"or\", song1_name)\n",
    "            print(\"Error:\", str(e))\n",
    "            break\n",
    "        comparing_counter+=1\n",
    "        if (comparing_counter%100000==0 \n",
    "            or comparing_counter==10 \n",
    "            or comparing_counter==50\n",
    "            or comparing_counter==100\n",
    "            or comparing_counter==500\n",
    "            or comparing_counter==1000\n",
    "            or comparing_counter==10000\n",
    "            or comparing_counter==50000\n",
    "           ):\n",
    "            print(str(datetime.now()) + \" Compared \" + str(comparing_counter) + \" songs.\")\n",
    "\n",
    "    print(str(datetime.now()) + \" Compared \" + str(comparing_counter) + \" pairs of songs.\")\n",
    "    print(\"Finished!\")\n",
    "    return comparing_data\n",
    "\n",
    "# Should rewrite to use only one data structure\n",
    "data_sample = {}\n",
    "sample_size = None\n",
    "if sample_size:\n",
    "    for f,d in all_data.items():\n",
    "        data_sample[f] = d\n",
    "        sample_size-=1\n",
    "        if sample_size <= 0:\n",
    "            break\n",
    "else:\n",
    "    data_sample = all_data\n",
    "            \n",
    "comp = compare_songs(make_combinations(data_sample), data_sample)\n",
    "print(\"\\nThe lower value, the closer style of songs.\")\n",
    "#print(comp[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[0:3]\n",
    "#dif_bands = comp.filter(comp['song1'].split(\"/\")[0] != comp['song1'].split(\"/\")[1]) \n",
    "comp.sort_values('dif').head(100).to_csv(path_or_buf=misuc_lib_path + \"/top100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = G=nx.from_numpy_matrix(comparing_data)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product join of all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "cut_path = len(misuc_lib_path)\n",
    "cd = [(c[0][cut_path:], c[1][cut_path:], c[2]) for c in comparing_data]\n",
    "sizes = [c[2] for c in cd]\n",
    "size_buckets = {}\n",
    "for s in sizes:\n",
    "    ns = int(s/10)\n",
    "    if ns in size_buckets:\n",
    "        size_buckets[ns] += 1\n",
    "    else:\n",
    "        size_buckets[ns] = 1\n",
    "\n",
    "pp.pprint(size_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_simil)\n",
    "top_simil.to_csv(index=True, path_or_buf=(misuc_lib_path + \"/Comparing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = req.get('https://lyrics.fandom.com/wiki/3_Doors_Down')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ganres\n",
    "b1 = bands[0]\n",
    "url = \"https://lyrics.fandom.com/wiki/\" + \"_\".join(b1.split(\" \"))\n",
    "r = req.get(url)\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing out ganres\n",
    "pq = PyQuery(r.content)\n",
    "print(pq)\n",
    "\n",
    "</div></div><div class=\"css-table-cell\">\n",
    "<p class=\"highlight\"><b>Genres:</b></p><div>\n",
    "<ul><li><a href=\"/wiki/Category:Genre/Alternative_Rock\" title=\"Category:Genre/Alternative Rock\">Alternative Rock</a>\n",
    "</li><li><a href=\"/wiki/Category:Genre/Pop_Rock\" title=\"Category:Genre/Pop Rock\">Pop Rock</a>\n",
    "</li><li><a href=\"/wiki/Category:Genre/Post-Grunge\" title=\"Category:Genre/Post-Grunge\">Post-Grunge</a>\n",
    "</li></ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
