{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import requests as req\n",
    "from pyquery import PyQuery\n",
    "from datetime import datetime\n",
    "import json\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is one part that is written not in Python: conversion mp3 to wav is done via Linux app called \"mpg321\" in function convert_mp3_to_wav. Everything else is Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_mp3s(path):\n",
    "    w = os.walk(path)\n",
    "    # folder / subfolders / files\n",
    "    all_files = []\n",
    "    for sw in w:\n",
    "        all_files += [sw[0] + \"/\" + x for x in sw[2]]\n",
    "    mp3_files = []\n",
    "    for f in all_files:\n",
    "        if f.split(\".\")[-1].upper() == \"MP3\": # Only taking mp3s\n",
    "            mp3_files.append(f)\n",
    "    return mp3_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(filename_mp3, filename_wav=None):\n",
    "    cd = os.getcwd()\n",
    "    if \"/\" not in filename_mp3: \n",
    "        filename_mp3 = cd + \"/\" + filename_mp3\n",
    "    filename_wav =  \".\".join(mp3_file.split(\".\")[0:-1]) + \".wav\"\n",
    "    subprocess.run([\"mpg321\", \"-w\", filename_wav, filename_mp3])\n",
    "    return filename_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_data(filepath, bucket_width=100):\n",
    "    \"\"\" \n",
    "    Data of wav file is very much about what I want to analyse. \n",
    "    So if you want to analyse in your own way, this is the function to change.\n",
    "    \"\"\"\n",
    "    fs, data = wavfile.read(filepath)\n",
    "    df_data = pd.DataFrame(data)\n",
    "    df_data['max'] = df_data.max(axis=1)\n",
    "    df_data['buckets'] = pd.Series(df_data['max']/bucket_width).astype(int)\n",
    "    bucket_sizes = df_data.groupby('buckets').size()\n",
    "    bucket_sizes = bucket_sizes.drop(bucket_sizes.idxmax())\n",
    "    return (bucket_sizes/max(bucket_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants and common variables\n",
    "misuc_lib_path = \"/MusicLib\" # Location of the library\n",
    "all_data = {} # Storage of data for analysis\n",
    "songs_cap = 10 # If you want only sample of a library\n",
    "full_data_dump_file_path = misuc_lib_path + \"/Full_Data.json\" # Your data dump file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_counter = 0\n",
    "convert_counter = 0\n",
    "for mp3_file in get_all_mp3s(misuc_lib_path):\n",
    "    wav_file = (\".\".join(mp3_file.split(\".\")[0:-1]) + \".wav\")\n",
    "    if not os.path.isfile(wav_file):\n",
    "        # I'm saving wav next to mp3, you can change it here.\n",
    "        wav_file = convert_mp3_to_wav(mp3_file, wav_file)\n",
    "        convert_counter+=1\n",
    "    wav_data = get_wav_data(wav_file,300)\n",
    "    # Can remove wav_files here!\n",
    "    #os.remove(wav_file)\n",
    "    all_data[mp3_file] = wav_data\n",
    "    process_counter+=1\n",
    "    if (process_counter%100 == 0):\n",
    "        print(datetime.now())\n",
    "        print(\"Processed \" + str(process_counter)\n",
    "              + \" songs, converted \" + str(convert_counter))\n",
    "    if process_counter==songs_cap: break\n",
    "print(\"Finished! Songs processed:\", len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dumping data into JSON\n",
    "with open(full_data_dump_file_path, 'w') as outfile:\n",
    "    json.dump(pd.DataFrame(all_data).to_json(), outfile)\n",
    "print(\"Data is dumped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading dumps\n",
    "with open(full_data_dump_file_path, 'r') as datafile:\n",
    "    all_data2 = json.loads(json.load(datafile)) # Be careful! Data loaded into new variable all_data2 !!!\n",
    "print(\"Loaded data for\",len(all_data),\"songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment starting from here\n",
    "### Everythin that follows is in very raw state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean names (shorten for convinience and memory optimization), saves as a separate dataframe\n",
    "cut_path_len = len(misuc_lib_path)\n",
    "\n",
    "#all_data_clean_dict = {\n",
    "#    k[cut_path_len:] : v\n",
    "#    for k, v in all_data.items()\n",
    "#}\n",
    "\n",
    "all_data_df = pd.DataFrame([(k[cut_path_len:], v) for k, v in all_data.items() ])\n",
    "print(\"Names are cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all combinations, to have list of comparisons.\n",
    "prodj = combinations(list(all_data_df[0]), 2)\n",
    "prodj = list(prodj)\n",
    "print(len(list(prodj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart_sample = 3 # Limit sample of songs to build charts\n",
    "for k, v in all_data.items():\n",
    "    if chart_sample > 0:\n",
    "        chart_sample-=1\n",
    "        print(k)\n",
    "        plt.plot(v)\n",
    "        plt.show()\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_data2\n",
    "type(all_data_clean_dict[0][0])\n",
    "#print(k,v)\n",
    "#a,b = prodj[0]\n",
    "#print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "print(\"Pairs to compare: \" + str(len(prodj)))\n",
    "\n",
    "comparing_data = []#pd.DataFrame()\n",
    "comparing_counter = 0\n",
    "for song1_name, song2_name in prodj:\n",
    "    comparing_counter+=1\n",
    "    if (comparing_counter%100000==0 \n",
    "        or comparing_counter==10 \n",
    "        or comparing_counter==50\n",
    "        or comparing_counter==100\n",
    "        or comparing_counter==500\n",
    "        or comparing_counter==1000\n",
    "        or comparing_counter==10000\n",
    "        or comparing_counter==50000\n",
    "       ):\n",
    "        print(str(datetime.now()) + \" Compared \" + str(comparing_counter) + \" songs.\")\n",
    "    if song1_name == song2_name:\n",
    "        print(\"Comparing to itself :(\")\n",
    "    result = pd.concat([\n",
    "        all_data_clean_dict[song1_name], \n",
    "        all_data_clean_dict[song2_name]], \n",
    "        axis=1, join='inner').fillna(0) #join_axes=[song1_data.index]\n",
    "    result['dif'] = abs(result[0] - result[1])\n",
    "    #print(str(sum(result['dif'])) + \" for \" + song2_name)\n",
    "    comparing_data.append((song1_name, song2_name, sum(result['dif'])))\n",
    "\n",
    "print(str(datetime.now()) + \" Compared \" + str(comparing_counter) + \" songs.\")\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys = list(all_data_df[0])\n",
    "index = all_data_df.index.union(all_data_df[0])\n",
    "all_data_df = all_data_df.reindex(index=index, columns=index, fill_value=0)\n",
    "print(all_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = G=nx.from_numpy_matrix(comparing_data)\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product join of all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter\n",
    "pp = PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "cut_path = len(misuc_lib_path)\n",
    "cd = [(c[0][cut_path:], c[1][cut_path:], c[2]) for c in comparing_data]\n",
    "sizes = [c[2] for c in cd]\n",
    "size_buckets = {}\n",
    "for s in sizes:\n",
    "    ns = int(s/10)\n",
    "    if ns in size_buckets:\n",
    "        size_buckets[ns] += 1\n",
    "    else:\n",
    "        size_buckets[ns] = 1\n",
    "\n",
    "pp.pprint(size_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_simil)\n",
    "top_simil.to_csv(index=True, path_or_buf=(misuc_lib_path + \"/Comparing.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = req.get('https://lyrics.fandom.com/wiki/3_Doors_Down')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ganres\n",
    "b1 = bands[0]\n",
    "url = \"https://lyrics.fandom.com/wiki/\" + \"_\".join(b1.split(\" \"))\n",
    "r = req.get(url)\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing out ganres\n",
    "pq = PyQuery(r.content)\n",
    "print(pq)\n",
    "\n",
    "</div></div><div class=\"css-table-cell\">\n",
    "<p class=\"highlight\"><b>Genres:</b></p><div>\n",
    "<ul><li><a href=\"/wiki/Category:Genre/Alternative_Rock\" title=\"Category:Genre/Alternative Rock\">Alternative Rock</a>\n",
    "</li><li><a href=\"/wiki/Category:Genre/Pop_Rock\" title=\"Category:Genre/Pop Rock\">Pop Rock</a>\n",
    "</li><li><a href=\"/wiki/Category:Genre/Post-Grunge\" title=\"Category:Genre/Post-Grunge\">Post-Grunge</a>\n",
    "</li></ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
